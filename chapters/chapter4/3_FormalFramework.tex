
\section{Quantifying Robustness}\label{chap4-sec:framework}

In this section, we present our formal framework for analyzing the robustness of a protocol for degree estimation. Specifically, we measure the robustness along two dimensions, \textit{correctness} (for honest users) and \textit{soundness} (for malicious users). Intuitively, good correctness means that the protocol is accurate for honest users, and good soundness means that it can detect/restrict malicious users. Hence, a protocol which has both properties is robust to poisoning attacks. %To the best of our knowledge, we are the first to analyze the correctness and soundness to \ldp~protocols for graphs. \ji{Is this right/adequate?}


\subsection{Metrics}\label{chap4-sec:robustframework}

%In order to achieve robustness, we permit our algorithms to return $\hat{d}_i = \bottom$ (abort the estimate for user $\DO_i$) if it detects poisoning in that user's data. The symbol $\bottom$ means that the data received about $\DO_i$ does not constitute a valid input and their degree estimate is aborted. 
Our notion of correctness guarantees that the protocol will produce an accurate degree estimate $\hat{d}_i$ for an honest user $\DO_i \in \mathcal{H}$ even under poisoning. On the other hand, good soundness prevents a malicious user $\DO_i \in \calM$ from  manipulating their degree estimate by too much \textit{without} detection.   We describe them in details as follows.  \vspace{-0.2cm}  
\\\\
\noindent\textbf{Correctness (For Honest Users).}
The \textit{correctness} of a protocol assesses its resilience to manipulation of an honest user's estimator. Specifically,  malicious users can adversely affect an honest user $\DO_i \in \calH$ by \squishlist\item tampering with the value of $\DO_i$'s degree estimate $\hat{d}_i$ (by introducing additional error), or \item attempting to mislabel $\DO_i$ as malicious (by influencing the aggregator to report $\hat{d}_i=\bot$) \squishend
Correctness protects the honest user $\DO_i$ along the above dimensions and is formally defined as follows:


\begin{defn}\label{chap4-def:correct}(\textbf{Correctness}) Let 
  $\langle R_1, \ldots, R_n\rangle$ be a non-interactive, \ldp{} protocol for degree estimation producing estimates $\langle \hd_1, \ldots, \hd_n\rangle$. Let $\calM$ be a set of malicious users with $|\calM| = m$ and $\calH$ be the set of honest users. 
Then, the protocol is defined to be $(\alpha_1,\delta_1)$-correct w.r.t. an attack from $\calM$ if for all input graphs $G\in \calG$ we have:
  \begin{gather}  \vspace{-0.2cm}  
    \forall \DO_i \in \calH, \mathrm{Pr}\left[\hat{d}_i = \bottom \vee
    |\hat{d}_i-d_i|\geq \alpha_1\right]\leq \delta_1,\label{chap4-eq:correct1}
  \end{gather}
where the above probability is taken w.r.t  the randomness in the protocol and the attack.
\end{defn}
The parameter $\alpha_1$ dictates the accuracy of the estimate $\hat{d}_i$, and the parameter $\delta_1$ dictates the chance of failure---that either of the aforementioned conditions fail to hold. Thus, if a protocol is $(\alpha_1,\delta_1)$-correct, it means that with probability at least $(1-\delta_1)$, 
the degree estimate $\hd_i$ for any honest user $\DO_i \in \calH$ has error \textit{at most} $\alpha_1$, \textit{and} $\DO_i$ is guaranteed to be \textit{not} mislabeled as malicious.

Complementary to the above definition, we introduce the notion of $\alpha_1$-\textit{tight correctness}. A protocol is defined to be $\alpha_1$-tight correct w.r.t an attack, if there exists a graph such that the attack is \textit{guaranteed} to either skew the  the degree estimate of at least one honest user by \textit{exactly} $\alpha_1$.  We use this definition to show the existence of strong attacks that are guaranteed to be very successful in manipulating the data of an honest user, which motivates the need for robust solutions. 

Lower the value of
$\alpha_1$ and $\delta_1$, better is the robustness of the protocol for honest users.  \vspace{-0.2cm}  \\\\ 
%This definition is the complement of Definition~\ref{chap4-def:correct}, and we use it to show that there are attacks which, in a strong sense, are very successful against the protocol: They are always able to return $\bottom$ or an inaccurate response for an honest user. We use this definition to motivate the need for more robust algorithms.\\\\
\noindent\textbf{Soundness (For Malicious Users). } The \textit{soundness} of a protocol assesses its ability to restrict adversarial manipulations of a malicious user's estimator. In particular, the protocol either returns an accurate estimate or returns $\hd_i = \bottom$ for these malicious users, regardless of the poisoning attack used. Formally, we use the following definition (which uses the complement event $\hd_i \neq \bottom \wedge |\hd_i - d_i| \geq \alpha_2$):

\begin{defn}\label{chap4-def:sound}(\textbf{Soundness}) Let $\langle R_1, \ldots, R_n\rangle$ be a non-interactive, \ldp{} protocol for degree estimation producing estimates $\hd_1, \ldots, \hd_n$. Let $\calM$ be a set of malicious users with $|\calM| = m$ and $\calH$ be the complement set of honest users. Then, the protocol is defined to be $(\alpha_2, \delta_2)$-sound w.r.t an attack from $\calM$ if, for all input graphs $G \in \calG$ we have
  \begin{gather}
    \forall \DO_i \in \calM, \mathrm{Pr}\left[\hd_i \neq \bottom \wedge |\hd_i -
    d_i| \geq \alpha_2\right]\leq \delta_2, \label{chap4-eq:sound1}
  \end{gather}
  where the above probability is taken w.r.t randomness in the protocol and attack.
\end{defn}
Like with correctness, the parameter $\alpha_2$ dictates the accuracy of the estimate $\hat{d}_i$, and $\delta_2$ dictates the chance of failure. As an important distinction, note that the failure event is when $\hat{d}_i$ is both $\neq \bottom$ \textit{and} is inaccurate, as stated above. Thus, the $\vee$ used in the definition of correctness is replaced by a $\wedge$. In other words, a protocol is $(\alpha_2,\delta_2)$-sound if for any malicious user $\DO_i, i \in \calM$, the protocol \squishlist \item fails to identify $\DO_i$ as malicious, \textit{and} \item reports its degree estimate $\hd_i$ with error \textit{greater} than $\alpha_2$ \squishend  with probability at most $\delta_2$.

Complementary to the above definition, we introduce the notion of $\alpha_1$-\textit{tight soundness}. A protocol is defined to be $\alpha_1$-tight sound w.r.t an attack if there exists a graph $G \in \calG$ such that at least one malicious user is \textit{guaranteed} to have their degree estimate misestimated by \textit{exactly} $\alpha_1$ \textit{without} getting detected.  %This is especially important in our context since every attack is trivially  $(n-1,1)$\footnote{We do not consider self-edges or loops in the graph.}-correct/sound. 
In other words, an $(n-1)$-tight sound/correct attack represents the strongest possible attack\footnote{We do not consider self-edges or loops in the graph.} -- an user's estimate can \textit{always} be skewed by the worst-case amount. We use this definition to motivate the need for more robust protocols. %Note that this is distinct from $(n-1,1)$ correct/sound which is trivial because all events occur with probability $<1$.
\par Lower the value of
$\alpha_2$ and lower the value of $\delta_2$, better is the robustness of the protocol for malicious users.  
  \vspace{-0.2cm}  \\\\
\noindent\textbf{Note.} Our proposed  framework strives to provide a strong notion of robustness -- not only are we able to guarantee accurate estimates, but also detect  \textit{and} flag individual malicious users (by reporting $\bottom$). %This is analogous to the guaranteed output delivery (GOD) model of security multi-party computation in cryptography~\cite{} which is the strongest security model.
%\arc{Expand on this}
\section{Impact of Poisoning on Baseline Protocols}

Within our robustness framework, we analyze the two naive private mechanisms outlined in Sec.~\ref{chap4-sec:ldp} -- the Laplace mechanism and randomized response. The shortcomings of these mechanisms motivate the design of our robust protocols discussed later in the paper. We present all our results for the stronger threat model of response poisoning attacks first. We defer all our discussion for the input poisoning attack to Sec. \ref{chap4-sec:input-attacks}. 

\subsection{Laplace Mechanism}

The simplest mechanism for estimating an user's degree is the Laplace mechanism, \RLap. Recall here, each user directly reports their noisy estimates. Consequently, the degree estimate of an honest user \textit{cannot} be tampered with at all -- the $\tilde{O}(\frac{1}{\epsilon})$\footnote{$\tilde{O}$ hides factors of $\log\frac{1}{\delta}$ } term is due to the error of the added Laplace noise. This error is in fact optimal (matches that of central \DP) for degree estimation.  On the flip side, a malicious user can flagrantly lie about their estimate without detection resulting in the the worst-case soundness guarantee. Specifically,  there
exists a graph and an attack against \RLap{} in
which a malicious user is guaranteed to manipulate their true degree by $n -1$ --
this holds for the case where the malicious user is an isolated node but
lies that their degree is $n - 1$. The robustness of \RLap{} against response poisoning attacks is formalized as follows: 
\begin{thm}\label{chap4-thm:response:laplace}
	Let $\calM$ be a set of malicious users with $|\calM| = m$. The \RLap{} protocol is $(\frac{1}{\epsilon}\log\frac{n}{\delta}),\delta)$-correct with respect to any response poisoning attack from $\calM$. However, there is a response poisoning attack $\calA$ such that \RLap{} is $(n-1)$-tight sound with respect to $\calA$.
\end{thm}
The proof of the above theorem is in App. \ref{chap4-app:thm:response:laplace}.
Thus according to our robustness framework, \RLap{} has good correctness but not soundness. Intuitively, \RLap{} fails to provide good soundness because there is no way to verify the malicious users' reports. 
It is important to note that  \RLap{} has good correctness guarantee even with $n-1$ malicious users while the worst-case soundness is inevitable even with a single malicious user. 
\subsection{Randomized Response}\label{chap4-sec:protocol:naive}
In this section, we look at an alternative mechanism where the users release their edges via randomized response. Recall that the information about an edge is shared between two users -- the idea here is to leverage this \textit{distributed information}. For our baseline algorithm, \DegRRNaive~(described in Alg.~\ref{chap4-alg:degrrnaive}), the data aggregator collects information about an edge from a \textit{single} user. Specifically, for edge $(i,j)$ with $i < j$, it simply uses the response from user $\DO_i$ to decide if the edge exists. To estimate the degree, it counts the total number of edges to user $\DO_i$ with the random variable $count_i^1$ and then computes a debiased estimate of the degree. Note that this naive approach is used by many prior works in local graph algorithms, such as~\cite{LDPGraph1, LDPGraph2,imola2021locally,imola_communication-efficient_2022}.
\setlength{\textfloatsep}{4pt}

\begin{algorithm}[t]
	\SetAlgoLined
  \KwData{$\{l_1,\cdots,l_n\}$ where $l_i \in \{0,1\}^n$ is the adjacency list of user $\DO_i$}
  \KwResult{$(\hat{d}_1,\cdots, \hat{d}_n)$ where $\hat{d}_i$ is the degree estimate for user $\DO_i$}
	
	\textbf{Users}\;
	\ForEach{$i \in [n]$}{
		$q_i = \rr_\rho(l_i)$\;
	}
	\textbf{Data Aggregator:}
	\ForEach{$i \in [n]$}{
    $count_i^1 = \sum_{j < i} q_j[i] + \sum_{i < j} q_i[j]$\;
    $\hd_i = \frac{1}{1-2\rho}(count^1_i - \rho (n-1))$\;
	}
\KwRet{$(\hd_1, \hd_2, \ldots, \hd_n)$}
\caption{\DegRRNaive$: \{0,1\}^{n\times n}\mapsto \{\mathbb{N}\cup \{\bot\}\}^n$}\label{chap4-alg:degrrnaive}

\end{algorithm}


% \begin{algorithm}
%  \caption{\DegRRNaive$: \{0,1\}^{n\times n}\mapsto \{\mathbb{N}\cup \{\bot\}\}^n$}\label{chap4-alg:degrrnaive}
%  \begin{algorithmic}[1]
%  \Statex \textbf{Parameter:} $\epsilon$ - Privacy parameter
%  \Statex \textbf{Input:} $\{l_1,\cdots,l_n\}$ where $l_i \in \{0,1\}^n$ is the adjacency \Statex \hspace{1.2cm} list of user $\DO_i$;
%  \Statex \textbf{Output:} $(\hat{d}_1,\cdots, \hat{d}_n)$ where $\hat{d}_i$ is the degree estimate for  \Statex \hspace{1.2cm} user $\DO_i$;
%  \Statex \textbf{Users}
%    \For{$i \in [n]$}
%      \State $q_i = \rr_\rho(l_i)$
%    \EndFor

%    \Statex \textbf{Data Aggregator}
%    \For{$i \in [n]$}
%      \State $count_i^1 = \sum_{j < i} q_j[i] + \sum_{i < j} q_i[j]$
%      \State $\hd_i = \frac{1}{1-2\rho}(count^1_i - \rho (n-1))$
%    \EndFor
%    \Return $(\hd_1, \hd_2, \ldots, \hd_n)$ 
% \end{algorithmic}
%\end{algorithm}

Formally
for response poisoning attacks, we have:
\begin{thm}\label{chap4-thm:b3a2_hard} 
Let $\calM$ be a set of malicious users with $|\calM| = m$. Then, 
the \DegRRNaive{} protocol is $(m\frac{e^\epsilon+1}{e^\epsilon-1}+\sqrt{n}\frac{\sqrt{(e^\epsilon+1)\ln\frac{2n}{\delta}}}{e^\epsilon-1},\delta)$-correct with respect to any response poisoning attack from $\calM$. However, there is a response poisoning attack $\calA$ such that \DegRRNaive{} is $(n-1)$-tight sound with respect to $\calA$.
\label{chap4-thm:response:naive}\end{thm}
The above theorem is proved in App. \ref{chap4-app:thm:response:naive}.
For $\epsilon < 1$, the correctness guarantee is $\approx m(1+\frac{1}{\epsilon})+\frac{\sqrt{n}}{\epsilon}$. Intuitively, the $\frac{\sqrt{n}}{\epsilon}$ term comes from the error introduced by randomized response. The $m(1+\frac{1}{\epsilon})$ term comes from the adversarial behavior of the malicious users -- $m$ term is inevitable and 
 accounts for the worst case scenario where all $m$ malicious users are colluding  (see Sec. \ref{chap4-sec:discussion}  for more details), while the $\frac{1}{\epsilon}$ factor corresponds to the scaling factor required for de-biasing. This observation is in line with prior work \cite{Cheu21} that assesses the impact of poisoning attacks on tabular data.  Clearly, smaller the value of $\epsilon$, worse is the impact of the attack.   %  who can carry out an increasingly strong attack with smaller $\epsilon$ since they can deterministically report $0$s for the edges to user $i$, not following randomized response which would dictate that $0$ or $1$ is returned with probability close to $\frac{1}{2}$. This harms the debiasing step used to compute $\hat{d}_i$.  %We will more completely discuss this phenomenon in later sections.


Similar to the Laplace mechanism, \DegRRNaive{} is $(n-1)$-tight sound, i.e., a malicious user can always get away with the worst-case $n-1$ error. This happens when $\DO_n$ is an isolated node who acts maliciously and reports an all-one list. Thus, once again this  worst-case soundness is inevitable even with a single malicious user.   In the next section, we discuss how to leverage the data redundancy in graphs and verify the data collected via randomized response to improve the soundness.

%\arc{Motivate what we do next} 


%As each edge is shared by two users, the edge information collected will contain two copies of the edge, one from each user. To decide whether to count an edge or not, our baseline  will simply take the edge information from one user. 
