
@misc{roychowdhury2021eiffel,
  doi = {10.48550/ARXIV.2112.12727},
  
  url = {https://arxiv.org/abs/2112.12727},
  
  author = {Roy Chowdhury, Amrita and Guo, Chuan and Jha, Somesh and van der Maaten, Laurens},
  
  keywords = {Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {EIFFeL: Ensuring Integrity for Federated Learning},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{Xie2020DBADB,
  title={DBA: Distributed Backdoor Attacks against Federated Learning},
  author={Chulin Xie and Keli Huang and Pin-Yu Chen and Bo Li},
  booktitle={ICLR},
  year={2020}
}
@inproceedings{kairouz2019advances,
  author={Peter Kairouz and H. Brendan McMahan and Brendan Avent and Aurelien Bellet and Mehdi Bennis and Arjun Nitin Bhagoji and Kallista Bonawitz and Zachary Charles and Graham Cormode and Rachel Cummings and Rafael G.L. D’Oliveira and Hubert Eichner and Salim El Rouayheb and David Evans and Josh Gardner and Zachary Garrett and Adria Gascon and Badih Ghazi and Phillip B. Gibbons and Marco Gruteser and Zaid Harchaoui and Chaoyang He and Lie He and Zhouyuan Huo and Ben Hutchinson and Justin Hsu and Martin Jaggi and Tara Javidi and Gauri Joshi and Mikhail Khodak and Jakub Konecny and Aleksandra Korolova and Farinaz Koushanfar and Sanmi Koyejo and Tancrede Lepoint and Yang Liu and Prateek Mittal and Mehryar Mohri and Richard Nock and Ayfer Ozgur and Rasmus Pagh and Hang Qi and Daniel Ramage and Ramesh Raskar and Mariana Raykova and Dawn Song and Weikang Song and Sebastian U. Stich and Ziteng Sun and Ananda Theertha Suresh and Florian Tramer and Praneeth Vepakomma and Jianyu Wang and Li Xiong and Zheng Xu and Qiang Yang and Felix X. Yu and Han Yu and Sen Zhao},
  title={Advances and Open Problems in Federated Learning},
  booktitle={arXiv:1912.04977},
  year={2019},
}
@inproceedings{Fang2020LocalMP,
  title={Local Model Poisoning Attacks to Byzantine-Robust Federated Learning},
  author={Minghong Fang and Xiaoyu Cao and Jinyuan Jia and Neil Zhenqiang Gong},
  booktitle={USENIX Security Symposium},
  year={2020}
} 
@inproceedings{burkhalter2021rofl,
  author={Lukas Burkhalter and Hidde Lycklama and Alexander Viand and Nicolas K{\"u}chler and Anwar Hithnawi},
  title={RoFL: Attestable Robustness for Secure Federated Learning},
  booktitle={arXiv:2107.03311},
  year={2021},
}
@inproceedings{sun2019backdoor,
  title={Can You Really Backdoor Federated Learning?},
  author={Ziteng Sun and Peter Kairouz and Ananda Theertha Suresh and H. Brendan McMahan},
  booktitle={arXiv:1911.07963},
  year={2019},
}

@inproceedings{bhagoji2019analyzing,
  author={Arjun Nitin Bhagoji and Supriyo Chakraborty and Prateek Mittal and Seraphin Calo},
  title={Analyzing federated learning through an adversarial lens},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={634--643},
  year={2019},
}

@inproceedings{bagdasaryan2018backdoor,
  author={Eugene Bagdasaryan and Andreas Veit and Yiqing Hua and Deborah Estrin and Vitaly Shmatikov},
  title={How to backdoor federated learning}, 
  booktitle={arXiv:1807.00459},
  year={2018},
}

@inproceedings{biggio2021poisoning,
  author={Battista Biggio and Blaine Nelson and Pavel Laskov},
  title={Poisoning attacks against support vector machines},
  booktitle={Proceedings of the International Coference on International Conference on Machine Learning},
  pages={1467--1474}, 
  year={2012},
}

@inproceedings{mei2015teaching,
  author={Shike Mei and Xiaojin Zhu},
  title={Using machine teaching to identify optimal training-set attacks on machine learners},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={2871--2877},
  year={2015},
}

@inproceedings{chen2017targeted,
  author={Xinyun Chen and Chang Liu and Bo Li and Kimberly Lu and Dawn Song},
  title={Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning},
  booktitle={arXiv:1712.05526},
  year={2017},
}



@misc{GDPR,
title={General Data Protection Regulation GDPR},
year={2016},
howpublished={\url {https://gdpr-info.eu/}}
}
@misc{ccpa,
title={California Consumer Privacy Act (CCPA)}, year={2018},
howpublished={\url {https://oag.ca.gov/privacy/ccpa}}
}

@inproceedings{Moran06,
author = {Moran, Tal and Naor, Moni},
title = {Polling with Physical Envelopes: A Rigorous Analysis of a Human-Centric Protocol},
year = {2006},
isbn = {3540345469},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11761679_7},
doi = {10.1007/11761679_7},
abstract = {We propose simple, realistic protocols for polling that allow the responder to plausibly repudiate his response, while at the same time allow accurate statistical analysis of poll results. The protocols use simple physical objects (envelopes or scratch-off cards) and can be performed without the aid of computers. One of the main innovations of this work is the use of techniques from theoretical cryptography to rigorously prove the security of a realistic, physical protocol. We show that, given a few properties of physical envelopes, the protocols are unconditionally secure in the universal composability framework.},
booktitle = {Proceedings of the 24th Annual International Conference on The Theory and Applications of Cryptographic Techniques},
pages = {88–108},
numpages = {21},
location = {St. Petersburg, Russia},
series = {EUROCRYPT'06}
}
@misc{Ambainis03,
  doi = {10.48550/ARXIV.CS/0302025},
  
  url = {https://arxiv.org/abs/cs/0302025},
  
  author = {Ambainis, Andris and Jakobsson, Markus and Lipmaa, Helger},
  
  keywords = {Computational Complexity (cs.CC), Cryptography and Security (cs.CR), Computers and Society (cs.CY), Quantum Physics (quant-ph), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Physical sciences, FOS: Physical sciences, D.4.6},
  
  title = {Cryptographic Randomized Response Techniques},
  
  publisher = {arXiv},
  
  year = {2003},
  
  copyright = {Assumed arXiv.org perpetual, non-exclusive license to distribute this article for submissions made before January 2004}
}

@INPROCEEDINGS{Cheu22,
  author={Cheu, Albert and Zhilyaev, Maxim},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)}, 
  title={Differentially Private Histograms in the Shuffle Model from Fake Users}, 
  year={2022},
  volume={},
  number={},
  pages={440-457},
  doi={10.1109/SP46214.2022.9833614}}

@misc{Li22,
  doi = {10.48550/ARXIV.2205.11782},
  
  url = {https://arxiv.org/abs/2205.11782},
  
  author = {Li, Xiaoguang and Gong, Neil Zhenqiang and Li, Ninghui and Sun, Wenhai and Li, Hui},
  
  keywords = {Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Fine-grained Poisoning Attacks to Local Differential Privacy Protocols for Mean and Variance Estimation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@inproceedings{FB,
author = {McAuley, Julian and Leskovec, Jure},
title = {Learning to Discover Social Circles in Ego Networks},
year = {2012},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
pages = {539–547},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'12}
}

@article{ER,
  title={On the evolution of random graphs},
  author={Erd{\H{o}}s, Paul and R{\'e}nyi, Alfr{\'e}d and others},
  journal={Publ. Math. Inst. Hung. Acad. Sci},
  volume={5},
  number={1},
  pages={17--60},
  year={1960}
}



@incollection{Microsoft,
title = {Collecting Telemetry Data Privately},
author = {Ding, Bolin and Kulkarni, Janardhan and Yekhanin, Sergey},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {3571--3580},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6948-collecting-telemetry-data-privately.pdf}
}

@article{Dwork,
 author = {Dwork, Cynthia and Roth, Aaron},
 title = {The Algorithmic Foundations of Differential Privacy},
 journal = {Found. Trends Theor. Comput. Sci.},
 issue_date = {August 2014},
 volume = {9},
 month = aug,
 year = {2014},
 issn = {1551-305X},
 pages = {211--407},
} 
@article{RR,
author={Warner, Stanley L},
title={Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias},
journal={Journal of the American Statistical Association}, volume={60 60, no. 309},year={ 1965}, pages={ 63-69} }

@article{Kato21,
  author    = {Fumiyuki Kato and
               Yang Cao and
               Masatoshi Yoshikawa},
  title     = {Preventing Manipulation Attack in Local Differential Privacy using
               Verifiable Randomization Mechanism},
  journal   = {CoRR},
  volume    = {abs/2104.06569},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.06569},
  eprinttype = {arXiv},
  eprint    = {2104.06569},
  timestamp = {Mon, 19 Apr 2021 16:45:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-06569.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{error2,
 author = {Chan, T-H. Hubert and Shi, Elaine and Song, Dawn},
 title = {Optimal Lower Bound for Differentially Private Multi-party Aggregation},
 booktitle = {Proceedings of the 20th Annual European Conference on Algorithms},
 series = {ESA'12},
 year = {2012},
 isbn = {978-3-642-33089-6},
 location = {Ljubljana, Slovenia},
 pages = {277--288},
 numpages = {12},
 url = {http://dx.doi.org/10.1007/978-3-642-33090-2_25},
 doi = {10.1007/978-3-642-33090-2_25},
 acmid = {2404185},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@inproceedings{error1,
 author = {Beimel, Amos and Nissim, Kobbi and Omri, Eran},
 title = {Distributed Private Data Analysis: Simultaneously Solving How and What},
 booktitle = {Proceedings of the 28th Annual Conference on Cryptology: Advances in Cryptology},
 series = {CRYPTO 2008},
 year = {2008},
 isbn = {978-3-540-85173-8},
 location = {Santa Barbara, CA, USA},
 pages = {451--468},
 numpages = {18},
 url = {http://dx.doi.org/10.1007/978-3-540-85174-5_25},
 doi = {10.1007/978-3-540-85174-5_25},
 acmid = {1429138},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@INPROCEEDINGS{error3, 
author={J. C. Duchi and M. I. Jordan and M. J. Wainwright}, 
booktitle={2013 IEEE 54th Annual Symposium on Foundations of Computer Science}, 
title={Local Privacy and Statistical Minimax Rates}, 
year={2013}, 
volume={}, 
number={}, 
pages={429-438}, 
keywords={data privacy;information theory;minimax techniques;statistical analysis;statistical minimax rates;differential privacy;statistical estimators;information-theoretic quantities;mutual information;Kullback-Leibler divergence;minimax techniques;local privacy constraints;location family models;convex risk minimization;privacy-preserving mechanisms;Privacy;Estimation;Data privacy;Zinc;Upper bound;Mutual information;TV;Differential privacy;minimax rates;estimation}, 
doi={10.1109/FOCS.2013.53}, 
ISSN={0272-5428}, 
month={Oct},}


@article{Apple,
	Author = {Andy Greenberg},
	Date-Added = {2018-08-21 19:59:41 -0400},
	Date-Modified = {2018-08-21 19:59:41 -0400},
	Journal = {Wired},
	Month = {Jun 13},
	Title = {Apple's `Differential Privacy' Is About Collecting Your Data---But Not {\em Your} Data},
	Year = {2016}}
	
	
@inproceedings{Rappor1,
	Author = {Erlingsson, {\'U}lfar and Pihur, Vasyl and Korolova, Aleksandra},
	Booktitle = {CCS},
	Date-Added = {2018-08-21 20:00:11 -0400},
	Date-Modified = {2018-08-21 20:00:11 -0400},
	Title = {Rappor: Randomized aggregatable privacy-preserving ordinal response},
	Year = {2014}}
	@article{EncryptedDP,
  title={Encrypted Databases for Differential Privacy},
  author={A. Agarwal and M. Herlihy and S. Kamara and Tarik Moataz},
  journal={Proceedings on Privacy Enhancing Technologies},
  year={2018},
  volume={2019},
  pages={170 - 190}
}

@misc{Rappor2,
    title={Building a RAPPOR with the Unknown: Privacy-Preserving Learning of Associations and Data Dictionaries},
    author={Giulia Fanti and Vasyl Pihur and {\'U}lfar Erlingsson},
    year={2015},
    eprint={1503.01214},
    archivePrefix={arXiv},
    primaryClass={cs.CR}
}


@article{Uber,
 author = {Johnson, Noah and Near, Joseph P. and Song, Dawn},
 title = {Towards Practical Differential Privacy for SQL Queries},
 journal = {Proc. VLDB Endow.},
 issue_date = {January 2018},
 volume = {11},
 number = {5},
 month = jan,
 year = {2018},
 issn = {2150-8097},
 pages = {526--539},
 numpages = {14},
 url = {https://doi.org/10.1145/3187009.3177733},
 doi = {10.1145/3187009.3177733},
 acmid = {3177733},
 publisher = {VLDB Endowment},
}

@misc{commercial3, title={Microsoft, Always Encrypted (Database Engine)
}, howpublished="\url{https:
//msdn.microsoft.com/en-us/library/mt163865.aspx/}",year={2016}}







@article{Graph1,
  title={The Johnson-Lindenstrauss Transform Itself Preserves Differential Privacy},
  author={Jeremiah Blocki and Avrim Blum and Anupam Datta and Or Sheffet},
  journal={2012 IEEE 53rd Annual Symposium on Foundations of Computer Science},
  year={2012},
  pages={410-419}
}
@article{Graph2,
  title={Publishing Community-Preserving Attributed Social Graphs with a Differential Privacy Guarantee},
  author={Xihui Chen and Sjouke Mauw and Yunior Ram{\'i}rez-Cruz},
  journal={Proceedings on Privacy Enhancing Technologies},
  year={2020},
  volume={2020},
  pages={131 - 152}
}
@INPROCEEDINGS{Graph3,
  author={Hay, Michael and Li, Chao and Miklau, Gerome and Jensen, David},
  booktitle={2009 Ninth IEEE International Conference on Data Mining}, 
  title={Accurate Estimation of the Degree Distribution of Private Networks}, 
  year={2009},
  volume={},
  number={},
  pages={169-178},
  doi={10.1109/ICDM.2009.11}}
  

@inproceedings{Graph4,
author = {Day, Wei-Yen and Li, Ninghui and Lyu, Min},
title = {Publishing Graph Degree Distribution with Node Differential Privacy},
year = {2016},
isbn = {9781450335317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2882903.2926745},
doi = {10.1145/2882903.2926745},
abstract = {Graph data publishing under node-differential privacy (node-DP) is challenging due to the huge sensitivity of queries. However, since a node in graph data oftentimes represents a person, node-DP is necessary to achieve personal data protection. In this paper, we investigate the problem of publishing the degree distribution of a graph under node-DP by exploring the projection approach to reduce the sensitivity. We propose two approaches based on aggregation and cumulative histogram to publish the degree distribution. The experiments demonstrate that our approaches greatly reduce the error of approximating the true degree distribution and have significant improvement over existing works. We also present the introspective analysis for understanding the factors of publishing the degree distribution with node-DP.},
booktitle = {Proceedings of the 2016 International Conference on Management of Data},
pages = {123–138},
numpages = {16},
keywords = {degree distribution, differential privacy, private graph publishing},
location = {San Francisco, California, USA},
series = {SIGMOD '16}
}

@article{Graph5,
author = {Karwa, Vishesh and Raskhodnikova, Sofya and Smith, Adam and Yaroslavtsev, Grigory},
title = {Private Analysis of Graph Structure},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0362-5915},
url = {https://doi.org/10.1145/2611523},
doi = {10.1145/2611523},
abstract = {We present efficient algorithms for releasing useful statistics about graph data while providing rigorous privacy guarantees. Our algorithms work on datasets that consist of relationships between individuals, such as social ties or email communication. The algorithms satisfy edge differential privacy, which essentially requires that the presence or absence of any particular relationship be hidden.Our algorithms output approximate answers to subgraph counting queries. Given a query graph H, for example, a triangle, k-star, or k-triangle, the goal is to return the number of edge-induced isomorphic copies of H in the input graph. The special case of triangles was considered by Nissim et al. [2007] and a more general investigation of arbitrary query graphs was initiated by Rastogi et al. [2009]. We extend the approach of Nissim et al. to a new class of statistics, namely k-star queries. We also give algorithms for k-triangle queries using a different approach based on the higher-order local sensitivity. For the specific graph statistics we consider (i.e., k-stars and k-triangles), we significantly improve on the work of Rastogi et al.: our algorithms satisfy a stronger notion of privacy that does not rely on the adversary having a particular prior distribution on the data, and add less noise to the answers before releasing them.We evaluate the accuracy of our algorithms both theoretically and empirically, using a variety of real and synthetic datasets. We give explicit, simple conditions under which these algorithms add a small amount of noise. We also provide the average-case analysis in the Erd\H{o}s-R\'{e}nyi-Gilbert G(n,p) random graph model.Finally, we give hardness results indicating that the approach Nissim et al. used for triangles cannot easily be extended to k-triangles (hence justifying our development of a new algorithmic approach).},
journal = {ACM Trans. Database Syst.},
month = {oct},
articleno = {22},
numpages = {33},
keywords = {Statistical data privacy, social network analysis, graph algorithms, differential privacy}
}

@inproceedings{Graph6,
  title={Analyzing Graphs with Node Differential Privacy},
  author={Shiva Prasad Kasiviswanathan and Kobbi Nissim and Sofya Raskhodnikova and Adam D. Smith},
  booktitle={TCC},
  year={2013}
}

@inproceedings{Graph7,
author = {Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
title = {Smooth Sensitivity and Sampling in Private Data Analysis},
year = {2007},
isbn = {9781595936318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1250790.1250803},
doi = {10.1145/1250790.1250803},
abstract = {We introduce a new, generic framework for private data analysis.The goal of private data analysis is to release aggregate information about a data set while protecting the privacy of the individuals whose information the data set contains.Our framework allows one to release functions f of the data withinstance-based additive noise. That is, the noise magnitude is determined not only by the function we want to release, but also bythe database itself. One of the challenges is to ensure that the noise magnitude does not leak information about the database. To address that, we calibrate the noise magnitude to the smoothsensitivity of f on the database x --- a measure of variabilityof f in the neighborhood of the instance x. The new frameworkgreatly expands the applicability of output perturbation, a technique for protecting individuals' privacy by adding a smallamount of random noise to the released statistics. To our knowledge, this is the first formal analysis of the effect of instance-basednoise in the context of data privacy.Our framework raises many interesting algorithmic questions. Namely,to apply the framework one must compute or approximate the smoothsensitivity of f on x. We show how to do this efficiently for several different functions, including the median and the cost ofthe minimum spanning tree. We also give a generic procedure based on sampling that allows one to release f(x) accurately on manydatabases x. This procedure is applicable even when no efficient algorithm for approximating smooth sensitivity of f is known orwhen f is given as a black box. We illustrate the procedure by applying it to k-SED (k-means) clustering and learning mixtures of Gaussians.},
booktitle = {Proceedings of the Thirty-Ninth Annual ACM Symposium on Theory of Computing},
pages = {75–84},
numpages = {10},
keywords = {privacy preserving data mining, clustering, private data analysis, output perturbation, sensitivity},
location = {San Diego, California, USA},
series = {STOC '07}
}

@article{Graph8,
author = {Karwa, Vishesh and Raskhodnikova, Sofya and Smith, Adam and Yaroslavtsev, Grigory},
title = {Private Analysis of Graph Structure},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0362-5915},
url = {https://doi.org/10.1145/2611523},
doi = {10.1145/2611523},
abstract = {We present efficient algorithms for releasing useful statistics about graph data while providing rigorous privacy guarantees. Our algorithms work on datasets that consist of relationships between individuals, such as social ties or email communication. The algorithms satisfy edge differential privacy, which essentially requires that the presence or absence of any particular relationship be hidden.Our algorithms output approximate answers to subgraph counting queries. Given a query graph H, for example, a triangle, k-star, or k-triangle, the goal is to return the number of edge-induced isomorphic copies of H in the input graph. The special case of triangles was considered by Nissim et al. [2007] and a more general investigation of arbitrary query graphs was initiated by Rastogi et al. [2009]. We extend the approach of Nissim et al. to a new class of statistics, namely k-star queries. We also give algorithms for k-triangle queries using a different approach based on the higher-order local sensitivity. For the specific graph statistics we consider (i.e., k-stars and k-triangles), we significantly improve on the work of Rastogi et al.: our algorithms satisfy a stronger notion of privacy that does not rely on the adversary having a particular prior distribution on the data, and add less noise to the answers before releasing them.We evaluate the accuracy of our algorithms both theoretically and empirically, using a variety of real and synthetic datasets. We give explicit, simple conditions under which these algorithms add a small amount of noise. We also provide the average-case analysis in the Erd\H{o}s-R\'{e}nyi-Gilbert G(n,p) random graph model.Finally, we give hardness results indicating that the approach Nissim et al. used for triangles cannot easily be extended to k-triangles (hence justifying our development of a new algorithmic approach).},
journal = {ACM Trans. Database Syst.},
month = {oct},
articleno = {22},
numpages = {33},
keywords = {differential privacy, graph algorithms, social network analysis, Statistical data privacy}
}

@article{Graph9,
  title={Differentially Private Continual Release of Graph Statistics},
  author={Shuang Song and Susan Little and Sanjay Mehta and Staal A. Vinterbo and Kamalika Chaudhuri},
  journal={ArXiv},
  year={2018},
  volume={abs/1809.02575}
}
@inproceedings{Graph10,
  title={Differential Privacy Preserving Spectral Graph Analysis},
  author={Yue Wang and Xintao Wu and Leting Wu},
  booktitle={PAKDD},
  year={2013}
}

@inproceedings{imola2021locally,
  title={Locally differentially private analysis of graph statistics},
  author={Imola, Jacob and Murakami, Takao and Chaudhuri, Kamalika},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={983--1000},
  year={2021}
}

@inproceedings{Andersen07,
author = {Andersen, Reid and Borgs, Christian and Chayes, Jennifer and Hopcraft, John and Mirrokni, Vahab S. and Teng, Shang-Hua},
title = {Local Computation of PageRank Contributions},
year = {2007},
isbn = {3540770038},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Motivated by the problem of detecting link-spam, we consider the following graph-theoretic primitive: Given a webgraph G, a vertex v in G, and a parameter δ ∈ (0, 1), compute the set of all vertices that contribute to v at least a δ fraction of v's PageRank. We call this set the δ-contributing set of v. To this end, we define the contribution vector of v to be the vector whose entries measure the contributions of every vertex to the PageRank of v. A local algorithm is one that produces a solution by adaptively examining only a small portion of the input graph near a specified vertex. We give an efficient local algorithm that computes an undefined-approximation of the contribution vector for a given vertex by adaptively examining O(1/undefined) vertices. Using this algorithm, we give a local approximation algorithm for the primitive defined above. Specifically, we give an algorithm that returns a set containing the δ-contributing set of v and at most O(1/δ) vertices from the δ/2-contributing set of v, and which does so by examining at most O(1/δ) vertices. We also give a local algorithm for solving the following problem: If there exist k vertices that contribute a ρ-fraction to the PageRank of v, find a set of k vertices that contribute at least a (ρ-undefined)-fraction to the PageRank of v. In this case, we prove that our algorithm examines at most O(k/undefined) vertices.},
booktitle = {Proceedings of the 5th International Conference on Algorithms and Models for the Web-Graph},
pages = {150–165},
numpages = {16},
location = {San Diego, CA, USA},
series = {WAW'07}
}

@INPROCEEDINGS{Cheu21,
  author={Cheu, Albert and Smith, Adam and Ullman, Jonathan},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)}, 
  title={Manipulation Attacks in Local Differential Privacy}, 
  year={2021},
  volume={},
  number={},
  pages={883-900},
  doi={10.1109/SP40001.2021.00001}}
  
  @inproceedings {Cao21,
author = {Xiaoyu Cao and Jinyuan Jia and Neil Zhenqiang Gong},
title = {Data Poisoning Attacks to Local Differential Privacy Protocols},
booktitle = {30th USENIX Security Symposium (USENIX Security 21)},
year = {2021},
isbn = {978-1-939133-24-3},
pages = {947--964},
url = {https://www.usenix.org/conference/usenixsecurity21/presentation/cao-xiaoyu},
publisher = {USENIX Association},
month = aug,
}
  @inproceedings{Fang18,
author = {Fang, Minghong and Yang, Guolei and Gong, Neil Zhenqiang and Liu, Jia},
title = {Poisoning Attacks to Graph-Based Recommender Systems},
year = {2018},
isbn = {9781450365697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3274694.3274706},
doi = {10.1145/3274694.3274706},
abstract = {Recommender system is an important component of many web services to help users locate items that match their interests. Several studies showed that recommender systems are vulnerable to poisoning attacks, in which an attacker injects fake data to a recommender system such that the system makes recommendations as the attacker desires. However, these poisoning attacks are either agnostic to recommendation algorithms or optimized to recommender systems (e.g., association-rule-based or matrix-factorization-based recommender systems) that are not graph-based. Like association-rule-based and matrix-factorization-based recommender systems, graph-based recommender system is also deployed in practice, e.g., eBay, Huawei App Store (a big app store in China). However, how to design optimized poisoning attacks for graph-based recommender systems is still an open problem.In this work, we perform a systematic study on poisoning attacks to graph-based recommender systems. We consider an attacker's goal is to promote a target item to be recommended to as many users as possible. To achieve this goal, our a"acks inject fake users with carefully crafted rating scores to the recommender system. Due to limited resources and to avoid detection, we assume the number of fake users that can be injected into the system is bounded. The key challenge is how to assign rating scores to the fake users such that the target item is recommended to as many normal users as possible. To address the challenge, we formulate the poisoning attacks as an optimization problem, solving which determines the rating scores for the fake users. We also propose techniques to solve the optimization problem. We evaluate our attacks and compare them with existing attacks under white-box (recommendation algorithm and its parameters are known), gray-box (recommendation algorithm is known but its parameters are unknown), and blackbox (recommendation algorithm is unknown) settings using two real-world datasets. Our results show that our attack is effective and outperforms existing attacks for graph-based recommender systems. For instance, when 1% of users are injected fake users, our attack can make a target item recommended to 580 times more normal users in certain scenarios.},
booktitle = {Proceedings of the 34th Annual Computer Security Applications Conference},
pages = {381–392},
numpages = {12},
keywords = {poisoning attacks, adversarial machine learning, Adversarial recommender systems},
location = {San Juan, PR, USA},
series = {ACSAC '18}
}
  @misc{Wu21,
  doi = {10.48550/ARXIV.2111.11534},
  
  url = {https://arxiv.org/abs/2111.11534},
  
  author = {Wu, Yongji and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil Zhenqiang},
  
  keywords = {Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@Inbook{Graph11,
author="Raskhodnikova, Sofya
and Smith, Adam",
title="Differentially Private Analysis of Graphs",
bookTitle="Encyclopedia of Algorithms",
year="2016",
publisher="Springer New York",
address="New York, NY",
pages="543--547",
isbn="978-1-4939-2864-4",
doi="10.1007/978-1-4939-2864-4_549",
url="https://doi.org/10.1007/978-1-4939-2864-4_549"
}

@inproceedings{LDPGraph1,
  title={Using Randomized Response for Differential Privacy Preserving Data Collection.},
  author={Wang, Yue and Wu, Xintao and Hu, Donghui},
  booktitle={EDBT/ICDT Workshops},
  volume={1558},
  pages={0090--6778},
  year={2016}
}

@inproceedings{LDPGraph2,
  title={Generating synthetic decentralized social graphs with local differential privacy},
  author={Qin, Zhan and Yu, Ting and Yang, Yin and Khalil, Issa and Xiao, Xiaokui and Ren, Kui},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={425--438},
  year={2017}
}

@inproceedings{LDPGraph3,
  title={Privacy at scale: Local differential privacy in practice},
  author={Cormode, Graham and Jha, Somesh and Kulkarni, Tejas and Li, Ninghui and Srivastava, Divesh and Wang, Tianhao},
  booktitle={Proceedings of the 2018 International Conference on Management of Data},
  pages={1655--1658},
  year={2018}
}

@inproceedings{LDPGraph4,
  title={Differentially-Private Control-Flow Node Coverage for Software Usage Analysis.},
  author={Zhang, Hailong and Latif, Sufian and Bassily, Raef and Rountev, Atanas},
  booktitle={USENIX Security Symposium},
  pages={1021--1038},
  year={2020}
}

@inproceedings{LDPGraph5,
  title={DPGraph: A Benchmark Platform for Differentially Private Graph Analysis},
  author={Xia, Siyuan and Chang, Beizhen and Knopf, Karl and He, Yihan and Tao, Yuchao and He, Xi},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={2808--2812},
  year={2021}
}

@article{LDPGraph6,
  title={Efficient publication of distributed and overlapping graph data under differential privacy},
  author={Zheng, Xu and Zhang, Lizong and Li, Kaiyang and Zeng, Xi},
  journal={Tsinghua Science and Technology},
  volume={27},
  number={2},
  pages={235--243},
  year={2021},
  publisher={TUP}
}
@article{imola_communication-efficient_2022,
  title = {Communication-{Efficient} {Triangle} {Counting} under {Local} {Differential} {Privacy}},
  url = {http://arxiv.org/abs/2110.06485},
  abstract = {Triangle counting in networks under LDP (Local Differential Privacy) is a fundamental task for analyzing connection patterns or calculating a clustering coefficient while strongly protecting sensitive friendships from a central server. In particular, a recent study proposes an algorithm for this task that uses two rounds of interaction between users and the server to significantly reduce estimation error. However, this algorithm suffers from a prohibitively high communication cost due to a large noisy graph each user needs to download. In this work, we propose triangle counting algorithms under LDP with a small estimation error and communication cost. We first propose two-rounds algorithms consisting of edge sampling and carefully selecting edges each user downloads so that the estimation error is small. Then we propose a double clipping technique, which clips the number of edges and then the number of noisy triangles, to significantly reduce the sensitivity of each user's query. Through comprehensive evaluation, we show that our algorithms dramatically reduce the communication cost of the existing algorithm, e.g., from 6 hours to 8 seconds or less at a 20 Mbps download rate, while keeping a small estimation error.},
  urldate = {2022-05-06}, 
  journal = {arXiv:2110.06485 [cs]},
  author = {Imola, Jacob and Murakami, Takao and Chaudhuri, Kamalika},
  month = jan, 
  year = {2022},
  note = {arXiv: 2110.06485},
  keywords = {Computer Science - Cryptography and Security, Computer Science - Databases},
  annote = {Comment: Full version of the paper accepted at USENIX Security 2022; The first and second authors made equal contribution},
  file = {arXiv Fulltext PDF:/home/jacob/Zotero/storage/HFVH94PR/Imola et al. - 2022 - Communication-Efficient Triangle Counting under Lo.pdf:application/pdf;arXiv.org Snapshot:/home/jacob/Zotero/storage/PW4B4848/2110.html:text/html},
}

@article{matsunaga2019exploring,
  title={Exploring graph neural networks for stock market predictions with rolling window analysis},
  author={Matsunaga, Daiki and Suzumura, Toyotaro and Takahashi, Toshihiro},
  journal={arXiv preprint arXiv:1909.10660},
  year={2019}
}

@inproceedings{benamira2019semi,
  title={Semi-supervised learning and graph neural networks for fake news detection},
  author={Benamira, Adrien and Devillers, Benjamin and Lesot, Etienne and Ray, Ayush K and Saadi, Manal and Malliaros, Fragkiskos D},
  booktitle={2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  pages={568--569},
  year={2019},
  organization={IEEE}
}

@article{gaudelet2021utilizing,
  title={Utilizing graph machine learning within drug discovery and development},
  author={Gaudelet, Thomas and Day, Ben and Jamasb, Arian R and Soman, Jyothish and Regep, Cristian and Liu, Gertrude and Hayter, Jeremy BR and Vickers, Richard and Roberts, Charles and Tang, Jian and others},
  journal={Briefings in bioinformatics},
  volume={22},
  number={6},
  pages={bbab159},
  year={2021},
  publisher={Oxford University Press}
}

@inproceedings{zhang2004making,
  title={Making eigenvector-based reputation systems robust to collusion},
  author={Zhang, Hui and Goel, Ashish and Govindan, Ramesh and Mason, Kahn and Van Roy, Benjamin},
  booktitle={Algorithms and Models for the Web-Graph: Third International Workshop, WAW 2004, Rome, Italy, October 16, 2004, Proceeedings 3},
  pages={92--104},
  year={2004},
  organization={Springer}
}

@ARTICLE{shenEnhancing2016,
  author={Shen, Haiying and Lin, Yuhua and Sapra, Karan and Li, Ze},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Enhancing Collusion Resilience in Reputation Systems}, 
  year={2016},
  volume={27},
  number={8},
  pages={2274-2287},
  doi={10.1109/TPDS.2015.2489198}}

  @article{arora2020analyzing,
  title={Analyzing and detecting collusive users involved in blackmarket retweeting activities},
  author={Arora, Udit and Dutta, Hridoy Sankar and Joshi, Brihi and Chetan, Aditya and Chakraborty, Tanmoy},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={11},
  number={3},
  pages={1--24},
  year={2020},
  publisher={ACM New York, NY, USA}
}
@article{dutta2022blackmarket,
  title={Blackmarket-driven collusion on online media: a survey},
  author={Dutta, Hridoy Sankar and Chakraborty, Tanmoy},
  journal={ACM/IMS Transactions on Data Science (TDS)},
  volume={2},
  number={4},
  pages={1--37},
  year={2022},
  publisher={ACM New York, NY}
}

@inproceedings{qin2017generating,
  title={Generating synthetic decentralized social graphs with local differential privacy},
  author={Qin, Zhan and Yu, Ting and Yang, Yin and Khalil, Issa and Xiao, Xiaokui and Ren, Kui},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={425--438},
  year={2017}
}
