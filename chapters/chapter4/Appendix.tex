\graphicspath{{./chapters/chapter4/}}
\chapter{ }

\section{Background Cntd.}\label{app:background}


\setlength{\textfloatsep}{2pt}
%\begin{algorithm}
%  \caption{$\rr_\rho: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:rr}
%  \begin{algorithmic}[1]
%  \Statex \textbf{Parameters:} $\epsilon$ - Privacy parameter;
%  
%  \Statex\textbf{Input:} $l \in \{0,1\}^n$ - True adjacency list;
%  \Statex \textbf{Output:} $q \in \{0,1\}^n$ - Reported (noisy) adjacency list;
%  \vspace{0.2cm}
%  \State $\rho=\frac{1}{1+e^{\epsilon}}$
%  \For{$i \in [n]$}
%  \State $q[i]=\rr_\rho(l[i])$
%  \EndFor
%  \Return $q$
%  \end{algorithmic}
%\end{algorithm}
\begin{algorithm}
  \KwData{$l \in \{0,1\}^n$ - True adjacency list}
  \KwResult{$q \in \{0,1\}^n$ - Reported (noisy) adjacency list}
  $\rho=\frac{1}{1+e^{\epsilon}}$\;
  \For{$i \in [n]$}{
  	$q[i]=\rr_\rho(l[i])$\;
	}
  \KwRet $q$
  \caption{$\rr_\rho: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:rr}
\end{algorithm}

\section{Proofs}\label{app:proofs}
First, we introduce notation and preliminary results used in our proofs.
\subsection{Notation} In this section, for a graph $G$ with vertices $[n]$, we let $d_i(S)$ for $S \subseteq [n]$ denote the number of neighbors of node $i$ in the set $S$.
We will often abuse notation for a set $\calS$ of users by also letting $\calS$ be the indices of the users in the set. Thus, we may let $i \in \calS$ be the index of some user in $\calS$.
Finally, we sometimes refer to user $\DO_i$ simply as user $i$.

\subsection{Preliminary Results}
We will heavily make use of the following concentration result:

\begin{lemma}\label{lem:bern-concentration}
    Let $X_1, \ldots, X_n$ denote independent random variables such that $X_i \sim \bern(p_i)$. Let $v = \sum_{i=1}^n p_i(1-p_i)$, and $X = \sum_{i=1}^n X_i$. Then,
    \begin{align*}
        \Pr[|X - \E[X]| \geq \max\{1.5 \ln \frac{2}{\delta}, \sqrt{2v\ln \frac{2}{\delta}}\}] &\leq \delta.
    \end{align*}
\end{lemma}
\begin{proof}
    Center the random variables so that $Z_i = X_i - p_i$; the variance $v$ does not change. We know by Bernstein's inequality that for all $t \geq 0$,
    \[
        \Pr[Z \geq t] \leq \exp\left(\frac{-t^2}{2(v + t / 3)}\right) \leq \exp\left(- \max \left\{ \frac{t^2}{2v}, \frac{3t}{2}\right\}\right).
    \]
    Thus, if $t \geq \max\{\frac{3}{2} \ln \frac{2}{\delta}, \sqrt{2 v \ln \frac{2}{\delta}}\}$, then $\Pr[Z \geq t] \leq \frac{\delta}{2}$. Applying the argument to $-Z$, we obtain the two-sized bound.
    
\end{proof}

Next, we observe the following facts about randomized response.
\begin{fact}\label{fact:rr-exp}
If user $i \in \calH$, then $\E[q_i[j]] = \rho + (1-2\rho) d_i(j)$.
\end{fact}

\begin{fact}\label{fact:2rr-exp}
If users $i,j \in \calH$, then $\E[q_i[j]q_j[i]] = \rho^2 + (1-2\rho) d_i(j)$.
\end{fact}
\subsection{Proof of Theorem \ref{thm:response:laplace}}\label{app:thm:response:laplace}
Recall that in the Laplace mechanism, a user's degree estimate $\hat{d}_i$ is simply $d_i + L_i$, where $L_i \sim Lap(\frac{1}{\epsilon})$ is a Laplace random variable generated by the user.\\\\\noindent
\textbf{Correctness.} The correctness guarantee follows from the concentration of Laplace distribution: Each Laplace random variable $L_i$ satisfies $|\Pr[|L_i| \geq t] \leq e^{-t\epsilon}$. Setting $t = \frac{1}{\epsilon}\ln \frac{n}{\delta}$ and applying the union bound, each of the $n$ Laplace variables will satisfy $|L_i| \leq \frac{1}{\epsilon}\ln \frac{\delta}{n}$ with probability $1-\delta$, and if this holds, then $|d_i - \hat{d}_i| \leq \frac{1}{\epsilon}\ln \frac{\delta}{n}$ for honest users.
\\
\noindent\textbf{Tight Soundness.} Consider the empty graph. A malicious user $\DO_i$ may report $n-1$, the maximum possible degree, and thus $\hat{d}_i = n-1$ while $d_i = 0$.

\subsection{Proof of Theorem~\ref{thm:response:naive}}\label{app:thm:response:naive}
\noindent \textbf{Correctness.}

As defined in \DegRRNaive{}, the estimator $count_i^1$ is given by 
\begin{gather}count^1_i=(\sum_{j < i} q_j[i] + \sum_{i < j} q_i[j])\end{gather}
We may alternatively split the above sum into honest bits and malicious bits as $count^1_i = hon_i + mal_i$. Here, 
\begin{gather*}
hon_i = \sum_{j < i, j \in \calH} q_j[i] + \sum_{i < j} q_i[j] \\
mal_i = \sum_{j < i, j \in \calM} q_j[i].
\end{gather*}
Since all bits in the sum $hon_i$ are honest, by Fact~\ref{fact:rr-exp} we have $\E[hon_i] = \rho|\calH_i| + (1-2\rho) d_i(\calH_i)$, where $\calH_i = \calH \cup \{1, 2, \ldots, i-1\}$. 

Furthermore, $0 \leq mal_i \leq |\calM_i|$, where $\calM_i = [n] \setminus \calH_i$. This implies $|mal_i - E_{mal,i}| \leq |\calM_i|$, where $E_{mal,i} = \rho|\calM_i| + (1-2\rho) d_i(\calM_i)$.
By Lemma~\ref{lem:bern-concentration} and a union bound, with probability $1-\delta$, we have for all $i \in \calH_i$ that
\begin{gather*}
\left|hon_i - \E[hon_i] + mal_i - E_{mal,i} \right| \leq  \sqrt{2\rho n \ln \frac{2n}{\delta}} + |\calM_i| \\ 
\implies \left|count_i^1 - \rho n - (1-2\rho)d_i \right| \leq  \sqrt{2\rho n \ln \frac{2n}{\delta}} + m \\ 
\implies |\hat{d}_i - d_i | \leq \frac{1}{1-2\rho} \sqrt{2\rho n \ln \frac{2n}{\delta}} + \frac{m}{1-2\rho}.
\end{gather*}

\noindent\textbf{Tight Soundness.} Consider the empty graph, and suppose that user $n$ is malicious. Since this user reports all his edges, he may report $q_i[j] = 1$ for all $j < 1$. Thus, $\hat{d}_n \geq n-1$, but $d_n = 0$, showing $n-1$-tight soundness.

\subsection{Proof of Theorem~\ref{thm:response:check}} \label{app:b3a3}
Recall the key quantities defined in \DegRRCheck{} (Algorithm~\ref{alg:degrrcheck}):
\begin{gather}
      count_i^{11} = \sum_{j \in [n] \setminus i} q_{i}[j] q_{j}[i] \\
      count_i^{01} = \sum_{j \in [n] \setminus i} (1-q_{i}[j])q_{j}[i].
\end{gather}
We now prove correctness.

\noindent \textbf{Correctness.} 
It will be helpful to split $count_i^{11} = hon_i^{11} + mal_i^{11}$, where $hon_i^{11} = \sum_{j \in \calH \setminus i} q_{i}[j] q_{j}[i]$ and $mal_i^{11} = \sum_{j \in \calM \setminus i} q_{ij} q_{ji}$. We define $hon_i^{01}$ and $mal_i^{01}$ similarly such that they satisfy $count_i^{01} = hon_i^{01} + mal_i^{01}$. We break the proof into two claims: showing that honest users receive an accurate estimate and that they are not disqualified.

\begin{claim}\label{claim:honest-response-concentration-1} We have
\[
    \Pr[\forall \DO_i \in \calH.~|\hat{d}_i - d_i| \geq \tfrac{m + 2 \sqrt{\rho n \ln \frac{4n}{\delta}}}{1-2\rho}] \leq \frac{\delta}{2}.
\]
\end{claim}
\begin{proof} 
Let $\DO_i \in \calH$. Then, $hon_i^{11}$ is a sum of $h-1$ Bernoulli random variables with $p = \rho^2$ or $(1-\rho)^2$. By Fact~\ref{fact:2rr-exp}, we have
\begin{align*}
    \E[hon_i^{11}] &= \rho^2 (h-1) + (1-2\rho) d_i(\calH)
\end{align*}
Now, $v$ defined in Lemma~\ref{lem:bern-concentration} satisfies $(h-1) \rho^2 \leq v \leq (h-1)(1-(1-\rho)^2) \leq 2(h-1)\rho$. Applying the Lemma and a union bound, we have with probability at least $1-\frac{\delta}{2}$ that for all $i \in \calH$,
\begin{equation}\label{eq:hon-player-bits}
    |hon_i^{11} - \E[hon_i^{11}]| \leq 2\sqrt{(h-1)\rho \ln \tfrac{4n}{\delta}}.
\end{equation}

On the other hand, we have that $0 \leq mal_i^{11} \leq m$, so if we let $E_{mal,i}^{11} = \rho^2 m + (1-2\rho) d_i(\calM)$ (defined for convenience later), then $|mal_i^{11} - E_{mal,i}^{11}| \leq m$.

Applying the triangle inequality, the following holds over all $i \in \calH$:
\begin{align*}
&|hon_i^{11} - \E[hon_i^{11}] + mal_i^{11} - E_{mal,i}^{11}|
\leq m + 2\sqrt{ \rho n \ln \tfrac{4n}{\delta}} \\
& \implies |count_i^{11} - \rho^2 (n-1) - (1-2\rho) d_i| \leq m + 2\sqrt{ \rho n \ln \tfrac{4n}{\delta}} \\
& \implies |\hat{d}_i - d_i| \leq \frac{m + 2\sqrt{ \rho n \ln \tfrac{4n}{\delta}}}{1-2\rho}
\end{align*}
This proves the claim.
\end{proof}
Next, we show that honest users are not likely to be disqualified.
\begin{claim}\label{claim:honest-response-concentration-2} We have
\[
    \Pr[\forall \DO_i \in \calH.~|count_i^{01} - \rho(1-\rho)(n-1)| \geq \tau] \leq \frac{\delta}{2},
\]
\end{claim}
where $\tau = m + \sqrt{2 \rho n \ln \frac{4 n}{\delta}}$

\begin{proof}
Let $\DO_i$ be honest. Then, the quantity $hon_i^{01}$ consists of $h-1$ Bernoulli random variables drawn from $\rho(1-\rho)$. We have
\[
    \E[hon_i^{01}] = \rho(1-\rho)(h-1).
\]
 As defined in Lemma~\ref{lem:bern-concentration}, $v$ satisfies $\frac{1}{2}(h-1)\rho \leq P \leq (h-1)\rho$.
Applying the Lemma and a union bound, we have with probability $1-\frac{\delta}{2}$ that for all $i \in \calH$, 
\begin{equation}\label{eq:hon-player-bits-2}
    |hon_i^{01} - \E[hon_i^{01}]| \leq \sqrt{2\rho (h-1) \ln \tfrac{4n}{\delta}}
\end{equation}
Noticing that $|mal_i^{01} - m \rho(1-\rho)| \leq m$, we have by the triangle inequality that
\[
    |count_i^{01} - \rho(1-\rho)(n-1)| \geq m + \sqrt{2\rho n \ln \tfrac{4n}{\delta}}.
\]
This concludes the proof.
\end{proof}
Putting it together,
$\left( m (\frac{e^\epsilon+1}{e^{\epsilon}-1}) + \sqrt{n}\frac{2 \sqrt{(e^\epsilon+1)\ln \frac{4n}{\delta}}}{e^\epsilon-1}, \delta\right)$-correctness follows.

\noindent \textbf{Soundness.} 

When player $i$ is a malicious player, we can still prove a tight bound on $count_{i}^{11} + count_{i}^{01}$, and this combined with the check in \DegRRNaive{} means that his degree estimate will be accurate.

\begin{claim}\label{claim:mal-response-concentration}
We have
\begin{multline*}
    \Pr[\forall i \in \calM.~|count_i^{11} + count_i^{01} \\ 
			-(1-2\rho)d_i - \rho(n-1)| \leq \tau ] \geq 1-\delta,
\end{multline*}
where $\tau = m + \sqrt{2 \rho n \ln \frac{4 n}{\delta}}$.
\end{claim}
\begin{proof}
Observe that $count_i^{11} + count_i^{01} = \sum_{j=1, j\neq i}^n q_{j}[i]$. Let $hon_i^{1}$ denote the sum of the $q_{j}[i]$ where $j$ is honest, and $mal_i^{1}$ denote the sum of the malicious players. By Fact~\ref{fact:rr-exp}, we have $\E[hon_i^1] = d_i(\calH) (1-2\rho) + h \rho$. Applying a union bound over Lemma~\ref{lem:bern-concentration}, for all $i \in \calM$, we have with probability at most $\delta$ that
\begin{equation}\label{eq:good-event-3}
    |hon_i^1 - \E[hon_i^1]| \geq \sqrt{2\rho n \ln \tfrac{2m}{\delta}}
\end{equation}
Because $|mal_i^1 - (1-2\rho)d_i(\calM) - \rho (m-1)| \leq m$, the claim follows from the triangle inequality.
\end{proof}

To conclude the proof, consider any malicious user $i \in \calM$ is not disqualified ($\hat{d}_i \neq \bottom$),
as if he is then the soundness event trivially happens. Thus, it must be true that $|count_i^{01} - (n-1)\rho(1-\rho)| \leq \tau$. However, given this and the event in Claim~\ref{claim:mal-response-concentration} holds, it follows by the triangle inequality that
\begin{align*}
    |count_i^{11}-(1-2\rho)d_i - \rho^2(n-1)| &\leq 2 \tau \\
    |\hat{d}_i - d_i| &\leq \frac{2 \tau }{1-2\rho}
\end{align*}
This establishes $\left( 2m (\frac{e^\epsilon+1}{e^{\epsilon}-1}) + 4\sqrt{n}\frac{ \sqrt{(e^\epsilon+1)\ln \frac{4n}{\delta}}}{e^\epsilon-1}, \delta\right)$-soundness.

\subsection{Proof of Theorem \ref{thm:no privacy}}\label{app:thm:no privacy}
\textbf{Correctness.}
Let honest $\DO_i$ share an edge with all malicious users in $\calM$. Now, all the malicious users can lie and report $0$ for $\DO_i$, i.e., set $q_j[i]=0 \forall j \in \calM$. This deflates $\DO_i$'s degree by $m$.
\\
\noindent \textbf{Soundness.} Let malicious $\DO_i$ share an edge with all users in the graph. Consider the attack where $\DO_i$ and $\DO_j, j \in \calM \setminus i$ report $0$ for their edges, and additionally $\DO_i$ reports $0$ for $\min\{m-1, n-m\}$ additional honest users. In this way, $\DO_i$ can deflate its degree estimate by $\min(2m-1,n)$.

\subsection{Proof of Theorem~\ref{thm:rrlapchecka3}}
\textbf{Correctness.}\label{app:thm:rrlapchecka3}
By Claim~\ref{claim:honest-response-concentration-2}, the first check in \DegHybrid{} will not set $\hat{d}_i = \bottom$ for any honest user with probability at least $1-\frac{\delta}{4}$. 
The variables $\hat{d}_i^{rr}$ in $\DegHybrid$ behave identically to $\hat{d}_i$ in \DegRRCheck{}. By Claim~\ref{claim:honest-response-concentration-1} 
we have for all users, $|\hat{d}_i^{rr} - d_i| \leq \frac{m + 2 \sqrt{\rho n \ln \frac{8n}{\delta}}}{1-2\rho}$,
with probability at least $1-\frac{\delta}{4}$. 

By concentration of Laplace random variables, we have for all $i \in \calH$ that $|\hat{d}_i^{lap} - d_i| \leq \frac{1}{\epsilon} \ln \frac{2n}{\delta}$ with probability at least $1-\frac{\delta}{2}$, 
and by the triangle inequality we have $|\hat{d}_i^{lap} - \hat{d}_i^{rr}| \leq \frac{m + 2 \sqrt{\rho n \ln \frac{8n}{\delta}}}{1-2\rho} + \frac{1}{\epsilon}\ln \frac{2n}{\delta}$. Thus, the second check will not set $\hat{d}_i = \bottom$ assuming these events hold, and the estimator $\hat{d}_i$ satisfies the correctness bound of $\hat{d}_i^{lap}$.

\textbf{Soundness.}
Following the same argument we saw in the soundness proof of Theorem~\ref{thm:response:check}, we can have that, with probability at least $1-\frac{\delta}{2}$, for all malicious users $i \in \calM$, we have $|\tilde{d}_i^{rr} - d_i| \leq \frac{2\tau}{1-2\rho}$. Suppose that $\hat{d}_i$ is not set to be $\bottom$. This implies that $|\tilde{d}_i^{rr} - \tilde{d}_i^{lap}| \leq \frac{2\tau}{1-2\rho} + \frac{1}{\epsilon}\log \frac{2n}{\delta}$.  By the triangle inequality, this implies
\[
    |\tilde{d}_i^{rr} - d_i| \leq \frac{4\tau}{1-2\rho} + \frac{1}{\epsilon} \log \frac{2n}{\delta}.
\]
This establishes $(\frac{4\tau}{1-2\rho} + \frac{1}{\epsilon} \log \frac{2n}{\delta}, \delta)$-soundness.

\subsection{Proof of Theorem~\ref{thm:input:laplace}}\label{app:thm:input:laplace}
\textbf{Correctness.} The correctness guarantee follows in the same way as Theorem~\ref{thm:response:laplace}.
\\
\noindent \textbf{Soundness.} Consider a malicious user $\DO_i$, and let $m_i$ be the malicious degree estimate sent by $\DO_i$, with $0 \leq m_i \leq n-1$. The estimator is given by $\hd_i = m_i+\eta, \eta \sim Lap(\frac{1}{\epsilon})$. 
Thus, $\Pr[|d_i - m_i - \eta| \geq n-1] \leq \Pr[\eta > 0] \leq \frac{1}{2}$.


\subsection{Proof of Theorem~\ref{thm:b2a2_easy}} \label{app:thm:b2a2_easy}
\noindent \textbf{Correctness.}
We follow the correctness proof of Theorem~\ref{thm:response:naive}, with the following change. Observe that $mal_i$ consists of $|\calM_i|$ Bernoulli random variables of mean either $\rho$ or $1-\rho$. Thus, with probability $1-\frac{\delta}{2}$, we have $|mal_i - \E[mal_i]| \leq \sqrt{2m\ln \frac{4m}{\delta}}$ for all $i \in \calM$. 

Thus, we can show $|mal_i - E_{mal,i}| \leq (1-2\rho) |\calM_i|$, where $E_{mal,i} = \rho |\calM_i| + (1-2\rho)d_i(M_i)$.
Finishing the proof, we can show 
\[
|\hat{d}_i - d_i | \leq \frac{1}{1-2\rho} (\sqrt{2\rho n \ln \tfrac{4n}{\delta}} + \sqrt{2m \ln \tfrac{4m}{\delta}}) + m.
\]
\noindent \textbf{Soundness.}

In order for $|d_i - \hat{d}_i| = n-1$, it is necessary for $|count_i^{1} - \rho(n-1) - (1-2\rho)d_i| \geq (1-2\rho)(n-1)$. We have $count_i^1$ is a sum of $n-1$ Bernoulli random variables of mean either $\rho$ or $1-\rho$, so it can be written as $\mu + Z_i$, where $Z_i$ is approximately a normal random variable of mean $0$. Observe that, since $\mu$ and $\rho(n-1) + (1-2\rho)d_i$ are in the interval $[\rho (n-1), (1-\rho)(n-1)]$, it is impossible for the difference $\mu - \rho(n-1) + (1-2\rho)d_i$ to exceed $(1-2\rho)(n-1)$ unless $Z_i$ has the correct sign, which happens with probability at most $\frac{1}{2}$. This establishes $(n-1, \frac{1}{2})$-soundness.
\subsection{Proof of Theorem~\ref{thm:input:check}}\label{app:b3a2}

\textbf{Correctness.}
Our proof follows that of Theorem~\ref{thm:response:check}. We are able to prove stronger versions of the claims.

\begin{claim}\label{claim:honest-input-concentration-1}
We have
\[
    \Pr[\forall i \in \calH.~|\hat{d}_i - d_i| \geq m+\frac{\sqrt{8\max\{\rho n, m\} \ln \frac{8n}{\delta}}}{1-2\rho}] \leq \frac{\delta}{2}.
\]
\end{claim}

\begin{proof}
We can control $hon_i^{11}$ in exactly the same way as in Claim~\ref{claim:honest-response-concentration-1}, so~\eqref{eq:hon-player-bits} holds with probability $1-\frac{\delta}{4}$, for all $i \in \calH$.
On the other hand, we know that $mal_i^{11}$ is now a sum of $d_i(\calM)$ Bernoulli random variables with bias either $(1-\rho)^2$ or $(1-\rho)\rho$, plus a sum of $m - d_i(\calM)$ Bernoulli random variables with bias either $\rho(1-\rho)$ or $\rho^2$. Thus, 
\begin{multline*}
	\rho(1-2\rho)d_i(\calM) + \rho^2 m \leq \E[mal_i^{11}] \\
	\leq (1-\rho)(1-2\rho)d_i(\calM) + \rho(1-\rho) m.
\end{multline*}
From this, we can show $|\E[mal_i^{11}] - E_{mal,i}^{11}| \leq (1-2\rho)m$, where $E_{mal,i}^{11} = \rho^2 m + (1-2\rho) d_i(\calM)$.
 Applying Hoeffding's inequality, we conclude that with probability at least $1 - \frac{\delta}{4}$, for all $i \in \calH$,
\[
    |mal_i^{11} - \E[mal_i^{11}]| \geq \sqrt{2m \ln \tfrac{8n}{\delta}}
\]
Thus, $|mal_i^{11} - E_{mal,i}^{11}| \leq (1-2\rho)m + \sqrt{2m \ln \tfrac{8n}{\delta}}$. Applying the triangle inequality, we obtain
\begin{multline*}
\Pr[|hon_i^{11} + mal_i^{11} - \E[hon_i^{11}] - E_{mal,i}^{11}| \\ \geq \sqrt{2m \ln \tfrac{8n}{\delta}} + (1-2\rho)m + 2\sqrt{ \rho n \ln \tfrac{8n}{\delta}}] \leq \tfrac{\delta}{2}.
\end{multline*}

The result follows in the same way as in Claim~\ref{claim:honest-response-concentration-1}.
\end{proof}

\begin{claim}\label{claim:honest-input-concentration-2}
We have
\[
    \Pr[\forall i \in \calH.~|count_i^{01} - \rho(1-\rho)(n-1)| \geq \tau] \leq \tfrac{\delta}{2},
\]
where $\tau = m(1-2\rho) + \sqrt{8 \max\{\rho n, m\} \ln \frac{8n}{\delta}}$.
\end{claim}

\begin{proof}
We can follow the same line of reasoning as Claim~\ref{claim:honest-response-concentration-2} and conclude that~\eqref{eq:hon-player-bits-2} holds.
Similar to Claim~\ref{claim:honest-input-concentration-1}, we can show that $|mal_i^{01} - \rho(1-\rho) m| \leq (1-2\rho)m + \sqrt{2m \ln \frac{8n}{\delta}}$ with probability at least $\frac{\delta}{4}$, and applying the triangle inequality, we see
\begin{multline*}
    \Pr[|count_i^{01} - \rho(1-\rho)n| \geq m(1-2\rho) + \\ \sqrt{2m \ln \tfrac{8n}{\delta}}  + \sqrt{2\rho n \ln \tfrac{8n}{\delta}}] \leq \tfrac{\delta}{2}.
\end{multline*}
\end{proof}

The $(2m+\frac{4\sqrt{2 \max\{\rho n, m\} \ln \frac{8n}{\delta}}}{1-2\rho}, \delta)$-correctness guarantee follows from the union bound over the two claims.

\textbf{Soundness.}
When player $i$ is a malicious player, he is still subject to the following claim:

\begin{claim}\label{claim:mal-input-concentration}
We have
\begin{multline*}
    \Pr[\forall i \in \calM.~|count_i^{11} + count_i^{01} \\ -(1-2\rho)d_i - \rho(n-1)| \leq \tau|] \geq 1-\delta,
\end{multline*}
where $\tau = m(1-2\rho) + \sqrt{8 \max\{\rho n, m\} \ln \frac{8n}{\delta}}$.
\end{claim}
\begin{proof}
Observe that $count_i^{11} + count_i^{01} = \sum_{j=1,j\neq i}^n q_{j}[i] = hon_i^1 + mal_i^1$. With the same argument as in Claim~\ref{claim:mal-response-concentration}, we know that~\eqref{eq:good-event-3} holds. Similarly, each random variable in $mal_i^1$ comes from either $\bern(\rho)$ or $\bern(1-\rho)$, and thus with probability at least $1-\frac{\delta}{2}$, for all $i \in \calM$
\[
    |mal_i^1 - \E[mal_i^1]| \leq \sqrt{2m \ln \tfrac{4m}{\delta}}
\]
Since $\E[mal_i^1] \in [\rho m, (1-\rho) m]$, 
This implies that $|mal_i^1 - \rho m | \leq  (1-2\rho)m + \sqrt{2m \ln \frac{4m}{\delta}}$. Thus, the claim follows.
\end{proof}

Having established this claim, we can prove $(2m + 4\sqrt{2 \max\{\rho n, m\} \ln \frac{8n}{\delta}}, \delta)$-soundness using an identical method as in the proof of soundness for Theorem~\ref{thm:response:check}.

\subsection{Proof of Theorem~\ref{thm:rrlapchecka2}}\label{app:thm:rrlapchecka2}
\textbf{Correctness.} As input manipulation attacks are a subset of response manipulation attacks, the same correctness guarantee as Theorem~\ref{thm:rrlapchecka3} holds.

\textbf{Soundness.}
The proof of this is similar to the soundness proof of Theorem~\ref{thm:rrlapchecka3}, using previous results in Theorem~\ref{thm:input:check}.

%In this model, a number of algorithms have been proposed for releasing subgraph counts [33, 35, 52], degree distributions [16, 27, 48], eigenvalues and eigenvectors [59], and synthetic graphs [15, 58].
%There has also been a handful of work on graph algorithms in the local DP model \cite{}. %For example, Qin et al. [46] propose an algorithm for generating synthetic graphs. Zhang et al. [65] propose an algorithm for software usage analysis under LDP, where a node represents a software com- ponent (e.g., function in a code) and an edge represents a


\section{Evaluation Cntd.}\label{app:attacks}
In this section, we describe the specific implementations of the attacks we use for our evaluation in Section \ref{sec:eval}.

\subsection{Attacks Against \DegRRCheck{}}

\subsubsection{Degree Inflation Attacks}
Let $\DO_t, t \in \calM$ denote the target malicious user. 
\\
\noindent\textbf{Input Poisoning.} In this attack, the non-target malicious users set the bit for $\DO_t$ to be $1$. The target malicious user constructs his input by setting $1$ for all other malicious users. They also report $1$ for honest users to which they share an edge. 

For honest users to which $\DO_t$ does not share an edge, $\DO_t$ flips some of the bits to $1$ with the hopes of artificially increasing his degree. He does this for a $r_1$-fraction of these neighbors. See Algorithm~\ref{alg:att-input-inf} for the details; we term this attack $A_{\DegRRCheck}^{inp}$. Note that if $r_1 = 0$, then the malicious user is being completely honest for these users and will not inflate his degree, and if $r_1 = 1$, then he lies about each of these users and will likely be caught. Thus, his strategy is to pick a value in between $0$ and $1$, and in the experiments we found that $r_1 = 15\%$ was a good tradeoff point.

%\begin{algorithm}[bt]
%  \caption{$A_{\DegRRCheck}^{inp}: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:att-input-inf}
%  \begin{algorithmic}[1]
%  \Statex \textbf{Parameters:} $\epsilon$ - Privacy parameter;
%  
%  %$RR_\rho(\cdot):\{0,1\} \mapsto \{0,1\}, \rho = \frac{1}{1+e^{2\epsilon}}$ -  Randomized response mechanism satisfying $\epsilon$-relation \DP
%  \Statex\textbf{Input:} $l \in \{0,1\}^n$ - True adjacency list;
%  \Statex \hspace{0.9cm} $t$ - Target honest user;
%  \Statex \textbf{Output:} $q \in \{0,1\}^n$ - Reported adjacency list;
%  \vspace{0.2cm}
%
%\State Select $r_1\in [0,1]$
%\State $\calH_1=\{i \in \calH| l[i]=1\}$ 
%\Statex \hfill\textcolor{blue}{$\rhd$} $\calH_1$ is the set of honest users with a mutual edge
%  \State $\calH_0=\calH\setminus\calH_1$
%  \Statex \hfill\textcolor{blue}{$\rhd$} $\calH_0$ is the set of honest users without a mutual edge
%    \State $F\in_R \calH_0, |F|=r_1|\calH_0|$
%    \Statex \hfill\textcolor{blue}{$\rhd$} Randomly sample $r_1$ fraction of the users in $\calH_0$ 
%    \State $l'=\{0,0,\cdots, 0\}$
%  \For{ $i \in \calH_1\cup\calM \cup F$} 
%  \State $l'[i]=1$ 
%  \EndFor
%  \For{$i \in [n]$}
%  \State $q[i]=\rr_\rho(l'[i])$
%  \EndFor
%  \Return $q$
%  \end{algorithmic}
%\end{algorithm}

\begin{algorithm}[bt]
\KwData{ $l \in \{0,1\}^n$ - True adjacency list, $t$ - Target honest user}
\KwResult{$q \in \{0,1\}^n$ - Reported adjacency list}
Select $r_1\in [0,1]$\;
$\calH_1=\{i \in \calH| l[i]=1\}$\;
\hfill\textcolor{blue}{$\rhd$} $\calH_1$ is the set of honest users with a mutual edge\;
$\calH_0=\calH\setminus\calH_1$\;
\hfill\textcolor{blue}{$\rhd$} $\calH_0$ is the set of honest users without a mutual edge\;
$F\in_R \calH_0, |F|=r_1|\calH_0|$\;
\hfill\textcolor{blue}{$\rhd$} Randomly sample $r_1$ fraction of the users in $\calH_0$\;
$l'=\{0,0,\cdots, 0\}$\;
\For{ $i \in \calH_1\cup\calM \cup F$} {
$l'[i]=1$ \;
}
\For{$i \in [n]$}{
	$q[i]=\rr_\rho(l'[i])$\;
}
\KwRet{$q$}
  \caption{$A_{\DegRRCheck}^{inp}: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:att-input-inf}
\end{algorithm}
\noindent \textbf{Response Poisoning.}  For response poisoning, the non-target malicious first find a plausible response by applying $RR_\rho$ to their data. They then set the bit for $\DO_t$ to be $1$, indicating they are connected to this user.

The target malicious user constructs his response by first applying $RR_\rho$ to his data to compute a plausible response. Then, he flips his bits to malicious users to $1$, and for honest users, he takes a $r_1$-fraction of the $0$s in his response and flips them to $1$. The quantity $r_1$ is a tradeoff parameter with the same intuition as for $A_{\DegRRCheck}^{inp}$. The details of this attack appear in Algorithm~\ref{alg:att-resp-inf}, and it is termed $A_{\DegRRCheck}^{resp}$.

%\begin{algorithm}[bt]
%  \caption{$A_{\DegRRCheck}^{resp}: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:att-resp-inf}
%  \begin{algorithmic}[1]
%  \Statex \textbf{Parameters:} $\epsilon$ - Privacy parameter;
%  
%  %$RR_\rho(\cdot):\{0,1\} \mapsto \{0,1\}, \rho = \frac{1}{1+e^{2\epsilon}}$ -  Randomized response mechanism satisfying $\epsilon$-relation \DP
%  \Statex\textbf{Input:} $l \in \{0,1\}^n$ - True adjacency list;
%  \Statex \textbf{Output:} $q \in \{0,1\}^n$ - Reported adjacency list;
%  \vspace{0.2cm}
%  
%  \State Select $r_1\in [0,1]$
%  \State $q = \textsf{RR}_\rho (l)$ 
%\State $\calI_1=\{i \in \calH| q[i]=1\}$ 
%\Statex \hfill\textcolor{blue}{$\rhd$} $\calH_1$ is the set of honest users with an edge in $q$
%\State $\calI_0 = \calH \setminus \calI_1$
%
%    \State $F\in_R \calI_0, |F|=r_1|\calI_0|$
%    \Statex \hfill\textcolor{blue}{$\rhd$} Randomly sample $r_1$ fraction of the users in $\calI_0$ 
%  \For{ $i \in \calI_1 \cup\calM \cup F$} 
%  \State $q[i]=1$ 
%  \EndFor
%  \Return $q$
%  \end{algorithmic}
%\end{algorithm}

\begin{algorithm}[bt]
\KwData{$l \in \{0,1\}^n$ - True adjacency list}
\KwResult{$q \in \{0,1\}^n$ - Reported adjacency list}
	Select $r_1\in [0,1]$\;
	$q = \textsf{RR}_\rho (l)$\;
	$\calI_1=\{i \in \calH| q[i]=1\}$\;
  \hfill\textcolor{blue}{$\rhd$} $\calH_1$ is the set of honest users with an edge in $q$\;
  $\calI_0 = \calH \setminus \calI_1$\;

  $F\in_R \calI_0, |F|=r_1|\calI_0|$\;
  \hfill\textcolor{blue}{$\rhd$} Randomly sample $r_1$ fraction of the users in $\calI_0$\;
  \For{ $i \in \calI_1 \cup\calM \cup F$}{
		$q[i]=1$\;
	}
  \KwRet{$q$}
  \caption{$A_{\DegRRCheck}^{resp}: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:att-resp-inf}
\end{algorithm}

\subsubsection{Degree Deflation Attacks}
Let $\DO_t, t \in \calH$ denote the target honest user. \\\noindent\textbf{Input Poisoning.} Here, every malicious user constructs his input acting honestly for non-target users and setting a $0$ for $\DO_t$.
\\\noindent\textbf{Response Poisoning.} 
Every malicious user acts honestly for non-target users by applying randomized response to their input. They finally send a $0$ for their connection to $\DO_t$.
\subsection{Attacks Against \DegHybrid{}}

\subsubsection{Degree Inflation Attacks}
Let $\DO_t, t \in \calM$ be the target malicious user.
\\
\noindent\textbf{Input Poisoning.} The non-target malicious users flip their edge to $\DO_t$ to a $1$ as they do in $A_{\DegRRCheck{}}^{inp}$. They send an honest estimate of their degree $\tilde{d}^{Lap}$ as this does not affect the target.

The target malicious user crafts his input adjacency list $q$ as he did in $A_{\DegRRCheck}^{inp}$. For his estimate $\tilde{d}_t^{Lap}$, he 
computes the expected value of $\tilde{d}_t^{rr}$ given that he submitted $q$ while the other users either submit $RR_\rho(l_i)$ or $RR_\rho(1)$, depending if they are honest or malicious. Specifically, the expected value is given by
\[
    e^{rr,inp} = \frac{m(1-\rho)^2 + \E[\sum_{i \in \calH} q_i RR_\rho(l_i)] - \rho^2 n}{1-2\rho}.
\]
He finally sets $\tilde{d}_t^{rr} = e_t^{rr,inp} + r_2 \frac{\tau}{1-2\rho}$ where $r_2 \in [0,1]$, which again trades off between how much cheating is possible and getting flagged. During the trials, we used $q_2 = 0.1$ as this did not significantly increase the target's chance of being rejected as $\bottom$. This attack, termed $A_{\DegHybrid}^{inp}$, appears in Algorithm~\ref{alg:att-resp-inf2}.

%\begin{algorithm}[bt]
%  \caption{$A_{\DegHybrid}^{inp}: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:att-resp-inf2}
%  \begin{algorithmic}[1]
%  \Statex \textbf{Parameters:} $\epsilon$ - Privacy parameter;
%
%  \Statex\textbf{Input:} $l \in \{0,1\}^n$ - True adjacency list;
%  \Statex \textbf{Output:} $q \in \{0,1\}^n$ - Reported adjacency list;
%  \Statex \hspace{1.1cm} $\tilde{d}^{lap}$ - Reported noisy degree estimate;
%  \vspace{0.2cm}
%\State{Select $r_2 \in [0,1]$}
%\State{$\rho = \frac{1}{1+e^{c\epsilon}}$}
%\Statex \hfill\textcolor{blue}{$\rhd$} $c$ is the constant used in Alg. \ref{alg:deghybrid} to divide the budget between the RR and Laplace steps.
%\State $q \gets A_{\DegRRCheck}^{inp}(l, c\epsilon)$
%
%\State $\tilde{count}^{11} \gets m(1-\rho)^2 + \E[\sum_{i \in \calH} q_i RR_\rho(l_i)]$
%\State $ e^{rr,inp} = \frac{\tilde{count}^{11} - \rho^2 n}{1-2\rho}$.
%\State $ \hat{d}^{Lap} = e^{rr,inp} + r_2 \frac{\tau}{1-2\rho} + \eta$ where $\eta \sim Lap(\frac{1}{(1-c)\epsilon})$.
%\Statex \textbf{return} $q,\tilde{d}^{Lap}$
%  \end{algorithmic}
%\end{algorithm}

\begin{algorithm}[bt]
	\KwData{$l \in \{0,1\}^n$ - True adjacency list}
	\KwResult{$q \in \{0,1\}^n$ - Reported adjacency list,  $\tilde{d}^{lap}$ - Reported noisy degree estimate}
	Select $r_2 \in [0,1]$\;
	$\rho = \frac{1}{1+e^{c\epsilon}}$\;
	\hfill\textcolor{blue}{$\rhd$} $c$ is the constant used in Alg. \ref{alg:deghybrid} to divide the budget between the RR and Laplace steps\;
	$q \gets A_{\DegRRCheck}^{inp}(l, c\epsilon)$\;
	$\tilde{count}^{11} \gets m(1-\rho)^2 + \E[\sum_{i \in \calH} q_i RR_\rho(l_i)]$\;
	$ e^{rr,inp} = \frac{\tilde{count}^{11} - \rho^2 n}{1-2\rho}$\;
	$ \hat{d}^{Lap} = e^{rr,inp} + r_2 \frac{\tau}{1-2\rho} + \eta$ where $\eta \sim Lap(\frac{1}{(1-c)\epsilon})$\;
	\KwRet{$q,\tilde{d}^{Lap}$}
\caption{$A_{\DegHybrid}^{inp}: \{0,1\}^n\mapsto\{0,1\}^n$ }\label{alg:att-resp-inf2}
\end{algorithm}

\noindent\textbf{Response Poisoning.}
The non-target malicious users flip their edge to $\DO_t$ to a $1$ as they do in $A_{\DegRRCheck{}}^{inp}$. They send an honest estimate of their degree $\tilde{d}^{Lap}$ as this does not affect the target.

The target malicious user crafts his response adjacency list $q$ as he did in $A_{\DegRRCheck}^{resp}$. For his estimate $\tilde{d}_t^{Lap}$, he computes the expected value of $\tilde{d}_t^{rr}$ given that he submitted $q$ while the other users either submit $RR_\rho(l_i)$ or $1$, depending if they are honest or malicious. This expected value is given by
\[
e^{rr, resp} = \frac{m + \E[\sum_{i \in \calH} q_i RR_\rho(l_i) - \rho^2 n]}{1-2\rho}.
\]
He finally sets $\tilde{d}_t^{rr} = e^{rr,resp} + r_2 \frac{\tau}{1-2\rho}$ where $r_2 \in [0,1]$ serves a similar tradeoff purpose as for $A_{\DegHybrid}^{inp}$. 

\begin{algorithm}[bt]
	\KwData{$l \in \{0,1\}^n$ - True adjacency list}
	\KwResult{$q \in \{0,1\}^n$ - Reported adjacency list, $\tilde{d}^{lap}$ - Reported noisy degree estimate}
  Select $r_2\in [0,1]$\;
	$q=A_{\DegRRCheck}^{resp}(l, \epsilon)$\;
	$\rho=\frac{1}{1+e^{c\epsilon}}$\;
	\hfill\textcolor{blue}{$\rhd$} $c$ determines how the privacy budget is divided between the two types of response as in Alg. \ref{alg:deghybrid}\;
	$\tilde{count}^{11} \gets m + \E[\sum_{i \in \calH} q_i RR_\rho(l_i)]$\;
	$e^{rr,resp} = \frac{m + \tilde{count}^{11} - \rho^2 n}{1-2\rho}$\;
	$\tilde{d}^{Lap} = e^{rr,resp} + r_2 \frac{\tau}{1-2\rho}$\;
	\KwRet{$q,\tilde{d}^{Lap}$}
  \caption{$A_{\DegHybrid}^{resp}: \{0,1\}^n\mapsto\{0,1\}^n$ }
\end{algorithm}

%\begin{algorithm}[bt]
%  \caption{$A_{\DegHybrid}^{resp}: \{0,1\}^n\mapsto\{0,1\}^n$ }
%  \begin{algorithmic}[1]
%  \Statex \textbf{Parameters:} $\epsilon$ - Privacy parameter
%  
%  %$RR_\rho(\cdot):\{0,1\} \mapsto \{0,1\}, \rho = \frac{1}{1+e^{2\epsilon}}$ -  Randomized response mechanism satisfying $\epsilon$-relation \DP
%  \Statex\textbf{Input:} $l \in \{0,1\}^n$ - True adjacency list;
%  \Statex \textbf{Output:} $q \in \{0,1\}^n$ - Reported adjacency list;
%   \Statex \hspace{1.1cm} $\tilde{d}^{lap}$ - Reported noisy degree estimate;
%  \vspace{0.2cm}
%  
%  \State Select $r_2\in [0,1]$ 
%\State $q=A_{\DegRRCheck}^{resp}(l, \epsilon)$
%\State $\rho=\frac{1}{1+e^{c\epsilon}}$
%\Statex \hfill\textcolor{blue}{$\rhd$} $c$ determines how the privacy budget is divided between the two types of response as in Alg. \ref{alg:deghybrid}
%\State $\tilde{count}^{11} \gets m + \E[\sum_{i \in \calH} q_i RR_\rho(l_i)]$
%\State $e^{rr,resp} = \frac{m + \tilde{count}^{11} - \rho^2 n}{1-2\rho}$
%\State $\tilde{d}^{Lap} = e^{rr,resp} + r_2 \frac{\tau}{1-2\rho}$
%\Statex \textbf{return} $q,\tilde{d}^{Lap}$
%  \end{algorithmic}
%\end{algorithm}


\subsubsection{Degree Deflation Attacks}
Let $\DO_t, t \in \calH$ represent the honest target.\\
\noindent\textbf{Input Poisoning.}
For the adjacency list, all the malicious users follow the same protocol as for \DegRRCheck{}. For the degree, all the malicious users follow the Laplace mechanism truthfully as these values are immaterial for estimating the degree of the target honest user.
  
\noindent\textbf{Response Poisoning.} 
For the adjacency list, all the malicious users follow the same protocol as for \DegRRCheck$(\cdot)$. For the degree, all the malicious users follow the Laplace mechanism truthfully as these values are immaterial for estimating the degree of the target honest user.

\subsection{Configurations Ctnd.}
Our theoretical results suggested setting $\tau = m + C\sqrt{\rho n}$, where $C$ is a constant that is obtained from Chernoff's bounds, for the different input and response manipulation attacks. The constant $C$ is not tight, and for the practical interest of using as small a threshold as possible, we sought to set $\tau$ as small as possible so as not to falsely flag any honest user. Note that lower the threshold, lower is the permissible skew ($\alpha_1$ and $\alpha_2$  for correctness  and  soundness, respectively) introduced by poisoning, thereby improving the robustness of our protocols. We ran preliminary experiments using $50$ runs of each protocol on both graphs, and we found that at all values of $\epsilon$, setting $\tau = m + 0.4\sqrt{\rho n}$ (for $m = 40$) and $\tau = m + 0.1 \sqrt{\rho n}$ (for $m = 1500$) did not result in any false positives. Thus, we used these smaller thresholds in our experiments, and throughout the experiments there were no false positives.
